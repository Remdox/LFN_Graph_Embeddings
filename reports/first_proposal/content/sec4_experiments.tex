\section{Experiments}
To compare the embedding methods, we first make a sample of the edges of the graph and then partition it into training, validition, test sets.
We then apply the embedding methods and use the models described in Sec\ref{sec:methods} to predict new links, and finally compare the predictions with the
edges which are not included in the sample. We employ each model for all embeddings, so that we can compare the impact of each one of them on the prediction of each model. \\ \newline
The implementations used are: \cite{} for  \\ \newline
Hardware used: \\ \newline
To evaluate the methods used in this project, two different evaluation measures will be used: the Area Under the Receiver Operating 
Characteristic curve (AUROC), and the Area Under the Precision-Recall curve (AUPR).
AUROC is historically considered the primary performance metric used to evaluate the performances of Link Prediction methods \cite{Kalyani2025}. 
However, AUROC favors accurate classification of positive examples, at the cost of misclassifying the negative ones.
In a scenario like Link Prediction problem, which is inherently skewed towards the negative class, it may not be suitable and can 
overestimate the performance of the methods. 
For this reason, the AUPR curve was also selected, as it can provide better evaluation of Link Prediction in the presence of class imbalance. \\ \newline
Finally, the metrics will be used to get relevant information about the quality of the embeddings. The results will be analyzed 
to assess how each embedding scales and adapts with different categories and sizes.